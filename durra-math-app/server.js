// server.js â€” fixed & debug-friendly
import 'dotenv/config';
import express from 'express';
import cors from 'cors';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const PORT = process.env.PORT || 3000;
const OPENAI_KEY = process.env.OPENAI_API_KEY;
const MODEL = process.env.OPENAI_CHAT_MODEL || 'gpt-4o-mini';

if (!OPENAI_KEY) {
  console.error('âš ï¸ OPENAI_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ .env. Ø£Ø¶Ù OPENAI_API_KEY Ø«Ù… Ø£Ø¹Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„.');
  // Ù„Ø§ Ù†ØºÙ„Ù‚ Ø§Ù„Ø®Ø§Ø¯Ù… ÙƒÙŠ ØªØ¨Ù‚Ù‰ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ØªØ¹Ù…Ù„ ÙˆØªØ¸Ù‡Ø± ØªØ­Ø°ÙŠØ±Ø§Ù‹ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„ØªØ¹Ø·Ù„
}

const app = express();
app.use(cors());
app.use(express.json({ limit: '2mb' }));

// Endpoint for health check
app.get('/ping', (req, res) => res.json({ ok: true, model: MODEL, hasKey: Boolean(OPENAI_KEY) }));

// Helper: call OpenAI Chat Completions REST
async function openaiChat(messages, model = MODEL) {
  if (!OPENAI_KEY) {
    return { error: { message: 'OPENAI_API_KEY Ù…ÙÙ‚ÙˆØ¯ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…' } };
  }
  const resp = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${OPENAI_KEY}`,
    },
    body: JSON.stringify({
      model,
      messages,
      temperature: 0.0,
      max_tokens: 1000,
    }),
  });
  const data = await resp.json().catch(() => ({}));
  return { status: resp.status, ok: resp.ok, data };
}

// Restrict to math only by simple system message (optional)
const systemPrompt = 'Ø£Ù†Øª Ù…Ø¹Ù„Ù…Ø© Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø°ÙƒÙŠØ©. Ø¬Ø§ÙˆØ¨ÙŠ Ø­ØµØ±ÙŠØ§Ù‹ Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ¨Ø§Ø®ØªØµØ§Ø± ÙˆØ§Ø¶Ø­ ÙˆØ®Ø·ÙˆØ§Øª ØµØ­ÙŠØ­Ø©. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø®Ø§Ø±Ø¬ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§ØªØŒ Ø§Ø¹ØªØ°Ø±ÙŠ ÙˆØ§Ø·Ù„Ø¨ÙŠ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø±ÙŠØ§Ø¶ÙŠØ§Ù‹.';

app.post('/api/chat', async (req, res) => {
  try {
    const { message, history } = req.body || {};
    if (!message) return res.status(400).json({ error: 'Ø­Ù‚Ù„ message Ù…Ø·Ù„ÙˆØ¨' });

    const messages = [{ role: 'system', content: systemPrompt }];
    if (Array.isArray(history)) {
      for (const h of history) {
        if (h.user) messages.push({ role: 'user', content: h.user });
        if (h.assistant) messages.push({ role: 'assistant', content: h.assistant });
      }
    }
    messages.push({ role: 'user', content: message });

    const result = await openaiChat(messages);
    if (result.error) {
      console.error('OpenAI missing key error:', result.error);
      return res.status(500).json({ error: 'Ù…ÙÙ‚ÙˆØ¯ Ù…ÙØªØ§Ø­ OpenAI Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø§Ø¯Ù…', details: result.error });
    }
    if (!result.ok) {
      console.error('OpenAI API error', result.status, result.data);
      return res.status(502).json({ error: 'Ø®Ø·Ø£ Ù…Ù† Ù…Ø²ÙˆÙ‘ÙØ¯ Ø§Ù„Ø®Ø¯Ù…Ø©', status: result.status, details: result.data });
    }
    const reply = result.data?.choices?.[0]?.message?.content ?? null;
    if (!reply) {
      console.warn('Unexpected OpenAI response shape:', result.data);
      return res.json({ reply: null, raw: result.data });
    }
    res.json({ reply });
  } catch (e) {
    console.error('Server /api/chat error:', e);
    res.status(500).json({ error: 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…', message: String(e) });
  }
});

// Serve static frontend
app.use(express.static(path.join(__dirname, 'public')));
app.get('*', (req, res) => res.sendFile(path.join(__dirname, 'public', 'index.html')));

app.listen(PORT, () => {
  console.log(`ðŸš€ Durra Math listening on http://localhost:${PORT}`);
});
